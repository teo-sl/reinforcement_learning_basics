{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.2.0 (SDL 2.0.22, Python 3.9.16)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from collections import deque\n",
    "import itertools\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from car import CarEnv,WIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.99               \n",
    "BATCH_SIZE = 64          \n",
    "BUFFER_SIZE = 100_000      \n",
    "MIN_REPLAY_SIZE = 1_000    \n",
    "EPSILON_START = 1.0 \n",
    "EPSILON_END = 0.1\n",
    "EPSILON_DECAY = 8_000      \n",
    "TARGET_UPDATE_FREQ = 1_000  \n",
    "LEARNING_RATE = 0.001\n",
    "TARGET_SAVE_FREQ = TARGET_UPDATE_FREQ*25\n",
    "MODELS_DIR = '../saved_models'\n",
    "LOG_DIR = '../logs/car_1_6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_writer = SummaryWriter(LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self,env):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(env.get_observation_space_size(), 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, env.get_action_space_size()),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    def act(self,obs):\n",
    "        obs_t = torch.as_tensor(obs, dtype=torch.float32)\n",
    "        q_values = self.forward(obs_t.unsqueeze(0))\n",
    "        max_q_index = torch.argmax(q_values, dim=1)[0]\n",
    "        action = max_q_index.detach().item()\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = CarEnv()\n",
    "\n",
    "replay_buffer = deque(maxlen=BUFFER_SIZE)\n",
    "\n",
    "reward_buffer = deque([],maxlen=100)\n",
    "score_buffer = deque([],maxlen=100)\n",
    "episode_reward = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_net = Network(env)\n",
    "target_net = Network(env)\n",
    "target_net.load_state_dict(online_net.state_dict())\n",
    "\n",
    "optimizer = torch.optim.Adam(online_net.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iniziatlize Replay Buffer\n",
    "obs = env.reset()\n",
    "\n",
    "for _ in range(MIN_REPLAY_SIZE):\n",
    "    action = env.sample_from_action_space()\n",
    "\n",
    "    new_obs, rew, done = env.step(action)    \n",
    "    \n",
    "    transition = (obs,action,rew,done,new_obs)\n",
    "    \n",
    "    replay_buffer.append(transition)\n",
    "    obs = new_obs\n",
    "\n",
    "    if done:\n",
    "        obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving target net\n",
      "\n",
      "Step 0\n",
      "Avg Rew nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/teodorosullazzo/opt/anaconda3/envs/pytorch_env_2/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/teodorosullazzo/opt/anaconda3/envs/pytorch_env_2/lib/python3.9/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 1000\n",
      "Avg Rew -87.7367409559585\n",
      "\n",
      "Step 2000\n",
      "Avg Rew -87.7367409559585\n",
      "\n",
      "Step 3000\n",
      "Avg Rew -87.7367409559585\n",
      "\n",
      "Step 4000\n",
      "Avg Rew -80.54849234688302\n",
      "\n",
      "Step 5000\n",
      "Avg Rew -41.57085173034121\n",
      "\n",
      "Step 6000\n",
      "Avg Rew -26.378842794889138\n",
      "\n",
      "Step 7000\n",
      "Avg Rew -12.256457665078695\n",
      "\n",
      "Step 8000\n",
      "Avg Rew -8.380464069641441\n",
      "\n",
      "Step 9000\n",
      "Avg Rew -8.380464069641441\n",
      "\n",
      "Step 10000\n",
      "Avg Rew -8.380464069641441\n",
      "\n",
      "Step 11000\n",
      "Avg Rew -8.912009046741204\n",
      "\n",
      "Step 12000\n",
      "Avg Rew 4.130005307190835\n",
      "\n",
      "Step 13000\n",
      "Avg Rew 16.319586036625328\n",
      "\n",
      "Step 14000\n",
      "Avg Rew 25.440877517069982\n",
      "\n",
      "Step 15000\n",
      "Avg Rew 33.924068853539055\n",
      "\n",
      "Step 16000\n",
      "Avg Rew 43.692683855437544\n",
      "\n",
      "Step 17000\n",
      "Avg Rew 53.31075056636097\n",
      "\n",
      "Step 18000\n",
      "Avg Rew 62.02252220216993\n",
      "\n",
      "Step 19000\n",
      "Avg Rew 71.45367262346524\n",
      "\n",
      "Step 20000\n",
      "Avg Rew 79.90988304458234\n",
      "\n",
      "Step 21000\n",
      "Avg Rew 87.56122529330077\n",
      "\n",
      "Step 22000\n",
      "Avg Rew 91.39879230205247\n",
      "\n",
      "Step 23000\n",
      "Avg Rew 96.90954631409575\n",
      "\n",
      "Step 24000\n",
      "Avg Rew 100.31261723976539\n",
      "Saving target net\n",
      "\n",
      "Step 25000\n",
      "Avg Rew 100.31261723976539\n",
      "\n",
      "Step 26000\n",
      "Avg Rew 100.31261723976539\n",
      "\n",
      "Step 27000\n",
      "Avg Rew 122.10333542638405\n",
      "\n",
      "Step 28000\n",
      "Avg Rew 134.08947774505162\n",
      "\n",
      "Step 29000\n",
      "Avg Rew 136.6578952091243\n",
      "\n",
      "Step 30000\n",
      "Avg Rew 143.80830184508224\n",
      "\n",
      "Step 31000\n",
      "Avg Rew 143.80830184508224\n",
      "\n",
      "Step 32000\n",
      "Avg Rew 143.80830184508224\n",
      "\n",
      "Step 33000\n",
      "Avg Rew 160.70975584180525\n",
      "\n",
      "Step 34000\n",
      "Avg Rew 160.70975584180525\n",
      "\n",
      "Step 35000\n",
      "Avg Rew 160.70975584180525\n",
      "\n",
      "Step 36000\n",
      "Avg Rew 179.17170135838512\n",
      "\n",
      "Step 37000\n",
      "Avg Rew 180.83478066349878\n",
      "\n",
      "Step 38000\n",
      "Avg Rew 180.83478066349878\n",
      "\n",
      "Step 39000\n",
      "Avg Rew 198.3221926611942\n",
      "\n",
      "Step 40000\n",
      "Avg Rew 200.95702129382914\n",
      "\n",
      "Step 41000\n",
      "Avg Rew 202.26052446394857\n",
      "\n",
      "Step 42000\n",
      "Avg Rew 204.80860581943867\n",
      "\n",
      "Step 43000\n",
      "Avg Rew 205.86541487432513\n",
      "\n",
      "Step 44000\n",
      "Avg Rew 213.23783497024962\n",
      "\n",
      "Step 45000\n",
      "Avg Rew 215.21011515426187\n",
      "\n",
      "Step 46000\n",
      "Avg Rew 217.74089097230964\n",
      "\n",
      "Step 47000\n",
      "Avg Rew 222.56772761120374\n",
      "\n",
      "Step 48000\n",
      "Avg Rew 222.56772761120374\n",
      "\n",
      "Step 49000\n",
      "Avg Rew 222.56772761120374\n",
      "Saving target net\n",
      "\n",
      "Step 50000\n",
      "Avg Rew 222.56772761120374\n",
      "\n",
      "Step 51000\n",
      "Avg Rew 222.56772761120374\n",
      "\n",
      "Step 52000\n",
      "Avg Rew 259.31095047161295\n",
      "\n",
      "Step 53000\n",
      "Avg Rew 258.76022045264347\n",
      "\n",
      "Step 54000\n",
      "Avg Rew 258.76022045264347\n",
      "\n",
      "Step 55000\n",
      "Avg Rew 260.06285873589115\n",
      "\n",
      "Step 56000\n",
      "Avg Rew 260.06285873589115\n",
      "\n",
      "Step 57000\n",
      "Avg Rew 260.06285873589115\n",
      "\n",
      "Step 58000\n",
      "Avg Rew 260.06285873589115\n",
      "\n",
      "Step 59000\n",
      "Avg Rew 252.68385775720859\n",
      "\n",
      "Step 60000\n",
      "Avg Rew 252.68385775720859\n",
      "\n",
      "Step 61000\n",
      "Avg Rew 252.68385775720859\n",
      "\n",
      "Step 62000\n",
      "Avg Rew 252.68385775720859\n",
      "\n",
      "Step 63000\n",
      "Avg Rew 259.4298834766582\n",
      "\n",
      "Step 64000\n",
      "Avg Rew 257.4458157365321\n",
      "\n",
      "Step 65000\n",
      "Avg Rew 257.4458157365321\n",
      "\n",
      "Step 66000\n",
      "Avg Rew 257.4458157365321\n",
      "\n",
      "Step 67000\n",
      "Avg Rew 257.7851657113884\n",
      "\n",
      "Step 68000\n",
      "Avg Rew 258.9956023312662\n",
      "\n",
      "Step 69000\n",
      "Avg Rew 261.195174404632\n",
      "\n",
      "Step 70000\n",
      "Avg Rew 260.3406771447282\n",
      "\n",
      "Step 71000\n",
      "Avg Rew 262.69043584605424\n",
      "\n",
      "Step 72000\n",
      "Avg Rew 262.8879029100675\n",
      "\n",
      "Step 73000\n",
      "Avg Rew 261.0632118374236\n",
      "\n",
      "Step 74000\n",
      "Avg Rew 258.53103393828974\n",
      "Saving target net\n",
      "\n",
      "Step 75000\n",
      "Avg Rew 257.8223473287682\n",
      "\n",
      "Step 76000\n",
      "Avg Rew 264.910946926447\n",
      "\n",
      "Step 77000\n",
      "Avg Rew 270.38732149322846\n",
      "\n",
      "Step 78000\n",
      "Avg Rew 274.0728786791536\n",
      "\n",
      "Step 79000\n",
      "Avg Rew 277.7162239788662\n",
      "\n",
      "Step 80000\n",
      "Avg Rew 281.4119490882554\n",
      "\n",
      "Step 81000\n",
      "Avg Rew 281.4119490882554\n",
      "\n",
      "Step 82000\n",
      "Avg Rew 286.259329970795\n",
      "\n",
      "Step 83000\n",
      "Avg Rew 290.7061881114696\n",
      "\n",
      "Step 84000\n",
      "Avg Rew 294.15623425884854\n",
      "\n",
      "Step 85000\n",
      "Avg Rew 297.75857939748306\n",
      "\n",
      "Step 86000\n",
      "Avg Rew 303.4216764816\n",
      "\n",
      "Step 87000\n",
      "Avg Rew 311.7442900253373\n",
      "\n",
      "Step 88000\n",
      "Avg Rew 311.7442900253373\n",
      "\n",
      "Step 89000\n",
      "Avg Rew 319.8002101483667\n",
      "\n",
      "Step 90000\n",
      "Avg Rew 322.87463634608883\n",
      "\n",
      "Step 91000\n",
      "Avg Rew 325.87194370610507\n",
      "\n",
      "Step 92000\n",
      "Avg Rew 328.95480174123617\n",
      "\n",
      "Step 93000\n",
      "Avg Rew 335.1701987467355\n",
      "\n",
      "Step 94000\n",
      "Avg Rew 338.3233565529337\n",
      "\n",
      "Step 95000\n",
      "Avg Rew 340.2185935801705\n",
      "\n",
      "Step 96000\n",
      "Avg Rew 345.41780749407275\n",
      "\n",
      "Step 97000\n",
      "Avg Rew 350.15839851728435\n",
      "\n",
      "Step 98000\n",
      "Avg Rew 353.61999818499714\n",
      "\n",
      "Step 99000\n",
      "Avg Rew 356.8601051789813\n",
      "Saving target net\n",
      "\n",
      "Step 100000\n",
      "Avg Rew 359.91801665200626\n",
      "\n",
      "Step 101000\n",
      "Avg Rew 359.91801665200626\n",
      "\n",
      "Step 102000\n",
      "Avg Rew 359.91801665200626\n",
      "\n",
      "Step 103000\n",
      "Avg Rew 359.91801665200626\n",
      "\n",
      "Step 104000\n",
      "Avg Rew 366.1430586244337\n",
      "\n",
      "Step 105000\n",
      "Avg Rew 369.07559676406163\n",
      "\n",
      "Step 106000\n",
      "Avg Rew 376.01240375982184\n",
      "\n",
      "Step 107000\n",
      "Avg Rew 376.24563788362116\n",
      "\n",
      "Step 108000\n",
      "Avg Rew 376.24563788362116\n",
      "\n",
      "Step 109000\n",
      "Avg Rew 376.24563788362116\n",
      "\n",
      "Step 110000\n",
      "Avg Rew 382.6478031429305\n",
      "\n",
      "Step 111000\n",
      "Avg Rew 385.2298522336728\n",
      "\n",
      "Step 112000\n",
      "Avg Rew 385.2298522336728\n",
      "\n",
      "Step 113000\n",
      "Avg Rew 394.77174540171916\n",
      "\n",
      "Step 114000\n",
      "Avg Rew 394.77174540171916\n",
      "\n",
      "Step 115000\n",
      "Avg Rew 394.77174540171916\n",
      "\n",
      "Step 116000\n",
      "Avg Rew 406.4081807012277\n",
      "\n",
      "Step 117000\n",
      "Avg Rew 406.4081807012277\n",
      "\n",
      "Step 118000\n",
      "Avg Rew 406.4081807012277\n",
      "\n",
      "Step 119000\n",
      "Avg Rew 412.6952556750042\n",
      "\n",
      "Step 120000\n",
      "Avg Rew 419.2136438271581\n",
      "\n",
      "Step 121000\n",
      "Avg Rew 423.01881141978987\n",
      "\n",
      "Step 122000\n",
      "Avg Rew 424.551904856718\n",
      "\n",
      "Step 123000\n",
      "Avg Rew 424.551904856718\n",
      "\n",
      "Step 124000\n",
      "Avg Rew 426.10648405849713\n",
      "Saving target net\n",
      "\n",
      "Step 125000\n",
      "Avg Rew 427.5478408353881\n",
      "\n",
      "Step 126000\n",
      "Avg Rew 430.3485434621623\n",
      "\n",
      "Step 127000\n",
      "Avg Rew 422.8605489533773\n",
      "\n",
      "Step 128000\n",
      "Avg Rew 419.7899681544718\n",
      "\n",
      "Step 129000\n",
      "Avg Rew 419.8011844471388\n",
      "\n",
      "Step 130000\n",
      "Avg Rew 418.5073793853761\n",
      "\n",
      "Step 131000\n",
      "Avg Rew 400.80477824683805\n",
      "\n",
      "Step 132000\n",
      "Avg Rew 400.8967139013632\n",
      "\n",
      "Step 133000\n",
      "Avg Rew 391.401542656475\n",
      "\n",
      "Step 134000\n",
      "Avg Rew 391.46839256622997\n",
      "\n",
      "Step 135000\n",
      "Avg Rew 391.46487647559667\n",
      "\n",
      "Step 136000\n",
      "Avg Rew 391.49842216191195\n",
      "\n",
      "Step 137000\n",
      "Avg Rew 389.1445371800274\n",
      "\n",
      "Step 138000\n",
      "Avg Rew 389.15637287893793\n",
      "\n",
      "Step 139000\n",
      "Avg Rew 388.65676310433776\n",
      "\n",
      "Step 140000\n",
      "Avg Rew 385.86521238589614\n",
      "\n",
      "Step 141000\n",
      "Avg Rew 385.86521238589614\n",
      "\n",
      "Step 142000\n",
      "Avg Rew 359.2091232105085\n",
      "\n",
      "Step 143000\n",
      "Avg Rew 359.8684553819144\n",
      "\n",
      "Step 144000\n",
      "Avg Rew 357.56841246779754\n",
      "\n",
      "Step 145000\n",
      "Avg Rew 365.6329831211113\n",
      "\n",
      "Step 146000\n",
      "Avg Rew 365.6329831211113\n",
      "\n",
      "Step 147000\n",
      "Avg Rew 370.25510300471694\n",
      "\n",
      "Step 148000\n",
      "Avg Rew 370.25510300471694\n",
      "\n",
      "Step 149000\n",
      "Avg Rew 370.537575308801\n",
      "Saving target net\n",
      "\n",
      "Step 150000\n",
      "Avg Rew 360.2300631695726\n",
      "\n",
      "Step 151000\n",
      "Avg Rew 357.07084229596927\n",
      "\n",
      "Step 152000\n",
      "Avg Rew 355.5384361972987\n",
      "\n",
      "Step 153000\n",
      "Avg Rew 355.5384361972987\n",
      "\n",
      "Step 154000\n",
      "Avg Rew 355.5384361972987\n",
      "\n",
      "Step 155000\n",
      "Avg Rew 355.5384361972987\n",
      "\n",
      "Step 156000\n",
      "Avg Rew 355.5384361972987\n",
      "\n",
      "Step 157000\n",
      "Avg Rew 355.5384361972987\n",
      "\n",
      "Step 158000\n",
      "Avg Rew 355.5384361972987\n",
      "\n",
      "Step 159000\n",
      "Avg Rew 355.5384361972987\n",
      "\n",
      "Step 160000\n",
      "Avg Rew 355.5384361972987\n",
      "\n",
      "Step 161000\n",
      "Avg Rew 355.5384361972987\n",
      "\n",
      "Step 162000\n",
      "Avg Rew 371.42644546090116\n",
      "\n",
      "Step 163000\n",
      "Avg Rew 371.42644546090116\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m     action \u001b[39m=\u001b[39m online_net\u001b[39m.\u001b[39mact(obs)\n\u001b[0;32m---> 14\u001b[0m new_obs, rew, done \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m     16\u001b[0m transition \u001b[39m=\u001b[39m (obs,action,rew,done,new_obs)\n\u001b[1;32m     17\u001b[0m replay_buffer\u001b[39m.\u001b[39mappend(transition)\n",
      "File \u001b[0;32m~/Documents/git_repos/self_driving/car/car.py:327\u001b[0m, in \u001b[0;36mCarEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mGame is over\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    325\u001b[0m reward \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m--> 327\u001b[0m draw(WIN, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimages, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mplayer_car)\n\u001b[1;32m    329\u001b[0m old_x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mplayer_car\u001b[39m.\u001b[39mx\n\u001b[1;32m    330\u001b[0m old_y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mplayer_car\u001b[39m.\u001b[39my\n",
      "File \u001b[0;32m~/Documents/git_repos/self_driving/car/car.py:110\u001b[0m, in \u001b[0;36mdraw\u001b[0;34m(win, images, player_car)\u001b[0m\n\u001b[1;32m    107\u001b[0m     win\u001b[39m.\u001b[39mblit(img, pos)\n\u001b[1;32m    109\u001b[0m player_car\u001b[39m.\u001b[39mdraw(win)\n\u001b[0;32m--> 110\u001b[0m pygame\u001b[39m.\u001b[39;49mdisplay\u001b[39m.\u001b[39;49mupdate()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "\n",
    "obs = env.reset()\n",
    "\n",
    "for step in itertools.count():\n",
    "    epsilon = np.interp(step,[0,EPSILON_DECAY],[EPSILON_START,EPSILON_END])\n",
    "    rnd_sample = random.random()\n",
    "\n",
    "    if rnd_sample < epsilon:\n",
    "        action = env.sample_from_action_space()\n",
    "    else:\n",
    "        action = online_net.act(obs)\n",
    "\n",
    "    new_obs, rew, done = env.step(action)\n",
    "\n",
    "    transition = (obs,action,rew,done,new_obs)\n",
    "    replay_buffer.append(transition)\n",
    "    obs = new_obs\n",
    "\n",
    "    episode_reward += rew\n",
    "\n",
    "    if done:\n",
    "        obs = env.reset()\n",
    "        reward_buffer.append(episode_reward)\n",
    "        episode_reward = 0.0\n",
    "\n",
    "\n",
    "    # start gradient step \n",
    "    transitions = random.sample(replay_buffer,BATCH_SIZE)\n",
    "    \n",
    "    obses = np.asarray([t[0] for t in transitions])\n",
    "    actions = np.asarray([t[1] for t in transitions])\n",
    "    rewards = np.asarray([t[2] for t in transitions])\n",
    "    dones = np.asarray([t[3] for t in transitions])\n",
    "    new_obses = np.asarray([t[4] for t in transitions])\n",
    "\n",
    "\n",
    "    obses_t = torch.as_tensor(obses, dtype=torch.float32)\n",
    "    \n",
    "    actions_t = torch.as_tensor(actions, dtype=torch.int64).unsqueeze(-1)\n",
    "    rewards_t = torch.as_tensor(rewards, dtype=torch.float32).unsqueeze(-1)\n",
    "    dones_t = torch.as_tensor(dones, dtype=torch.float32).unsqueeze(-1)\n",
    "    new_obses_t = torch.as_tensor(new_obses, dtype=torch.float32)\n",
    "\n",
    "    # compute targets\n",
    "\n",
    "    target_q_values = target_net(new_obses_t)\n",
    "\n",
    "    max_target_q_values = target_q_values.max(dim=1,keepdim=True)[0]\n",
    "\n",
    "    targets = rewards_t + GAMMA * (1-dones_t) * max_target_q_values\n",
    "\n",
    "    # loss\n",
    "\n",
    "    q_values = online_net(obses_t)\n",
    "\n",
    "    action_q_values = torch.gather(input = q_values, dim=1, index = actions_t)\n",
    "\n",
    "    loss = nn.functional.smooth_l1_loss(action_q_values,targets)\n",
    "\n",
    "    # gradient step\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # update target network if needed\n",
    "    if step % TARGET_UPDATE_FREQ == 0:\n",
    "        target_net.load_state_dict(online_net.state_dict())\n",
    "        \n",
    "    # checkpointing\n",
    "    if step % TARGET_SAVE_FREQ == 0:\n",
    "        print(\"Saving target net\")\n",
    "        torch.save(target_net.state_dict(), MODELS_DIR+\"/snake_target_net_.pth\")\n",
    "    \n",
    "    # Logging\n",
    "    if step % 1000 == 0:\n",
    "        rew_mean = np.mean(reward_buffer)\n",
    "        print()\n",
    "        print('Step', step)\n",
    "        print('Avg Rew',rew_mean)\n",
    "        summary_writer.add_scalar('avg_rew', rew_mean, global_step=step)\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
